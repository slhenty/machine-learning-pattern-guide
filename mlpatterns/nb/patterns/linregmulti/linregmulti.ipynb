{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.816036Z",
     "start_time": "2022-04-09T18:04:27.804314Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_area .rendered_html table{margin-left:0;margin-right:auto;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlpatterns.util._style_init_ import align_output_tables\n",
    "align_output_tables('left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[(< index)](../../Guide.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large\n",
    "\\begin{align}\n",
    "&&&\\boxed {\\textbf{WIP}}&\n",
    "&&&\\boxed {\\textbf{WIP}}&\n",
    "&&&\\boxed {\\textbf{WIP}}&\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Linear Regression - multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.891587Z",
     "start_time": "2022-04-09T18:04:27.818350Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": true,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Abbreviation | Architecture                                     |    Type    | Use                   | Limitation                               |\n",
       "|:------------:|:-------------------------------------------------|:----------:|:----------------------|:-----------------------------------------|\n",
       "    |  linregmulti   | Polynomial in multiple variables (aka 'input features') | Supervised | Real value prediction | Underfits non-linear data<br>(high bias) |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./_summary_.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<u>_Objective_</u>\n",
    "- Tune a polynomial that takes the input features, and returns a predicted output value\n",
    "\n",
    "<u>_Learning algorithm_</u>\n",
    "- Gradient descent\n",
    "\n",
    "<u>_Parameters_</u>\n",
    "- polynomial co-efficients, $\\theta$\n",
    "\n",
    "<u>_Hyper-parameters_</u>\n",
    "- learning rate, alpha: $\\alpha$\n",
    "- polynomial degree / higher-order terms: $x_{j}^{p}x_{k}^{q} ... x_{n}^{s}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.909475Z",
     "start_time": "2022-04-09T18:04:27.893567Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Packages needed for the examples\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Packages needed for the examples\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.912607Z",
     "start_time": "2022-04-09T18:04:27.912574Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "linreg_x = np.array([[2, 3, 432], [3, 4, 543], [5, 6, 765]])\n",
    "linreg_y = np.array([[11, 17, 29]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Forward function / Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> $\\normalsize\n",
    "\\begin{align}\n",
    "h_{\\theta}(x) &= \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_{n-1} x_{n-1} + \\theta_n x_n \\\\\n",
    "  &= \\theta \\cdot x \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "> where,\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta &\\text{ is a row vector of coefficients (parameters) of the polynomial } h_{\\theta}(x) \\\\\n",
    "x &\\text{ is a col vector with } x_0 \\text{ set to } 1\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> **Example linreguni-1:**\n",
    ">\n",
    "> Given,\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta &= \\begin{bmatrix}\n",
    "0.2 & 0.5 & 0.7 & 0.1\n",
    "\\end{bmatrix}\n",
    ",\\;\n",
    "x = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "387\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "> Then,\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta \\cdot x &= \\begin{bmatrix} (\\theta_{[0,0]} \\times x_{[0,0]}) + (\\theta_{[0,1]} \\times x_{[1,0]}) + (\\theta_{[0,2]} \\times x_{[2,0]}) + (\\theta_{[0,3]} \\times x_{[3,0]}) \\end{bmatrix} \\\\\n",
    "  \\;&= \\begin{bmatrix} (0.2 \\times 1) + (0.5 \\times 2) + (0.7 \\times 3) + (0.1 \\times 387) \\end{bmatrix} \\\\\n",
    "  \\;&= \\begin{bmatrix} 0.2 + 1 + 2.1 + 38.7 \\end{bmatrix} \\\\\n",
    "  \\;&= \\begin{bmatrix} 42 \\end{bmatrix}\n",
    "\\end{align}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.914444Z",
     "start_time": "2022-04-09T18:04:27.914423Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linreg_h_theta(theta, features):\n",
    "    \"\"\"\n",
    "    :param theta: Row vector of polynomial coefficients (i.e. parameters)\n",
    "    :param features: Col vector of features, with x_0 set to 1 (i.e. bias term)\n",
    "    :return: Estimate of y (i.e. y_hat)\n",
    "    \"\"\"\n",
    "\n",
    "    y_hat = np.dot(theta, features)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta (shape):  (1, 2)\n",
      "[[2. 5.]] \n",
      "\n",
      "x (shape):  (1, 1)\n",
      "[[2]] \n",
      "\n",
      "X (shape) with bias terms:  (2, 1)\n",
      "[[1.]\n",
      " [2.]] \n",
      "\n",
      "y_hat (shape):  (1, 1)\n",
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "# linreguni-fw Example\n",
    "\n",
    "theta = np.array([[2., 5.]])\n",
    "x = np.array(linreg_x[:, 0:1])\n",
    "x_bias = np.ones((1, x.shape[1]))\n",
    "X = np.vstack((x_bias, x))\n",
    "print('theta (shape): ', theta.shape)\n",
    "print(theta, '\\n')\n",
    "print('x (shape): ', x.shape)\n",
    "print(x, '\\n')\n",
    "print('X (shape) with bias terms: ', X.shape)\n",
    "print(X, '\\n')\n",
    "\n",
    "y_hat = linreg_h_theta(theta, X)\n",
    "print('y_hat (shape): ', y_hat.shape)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Vectorized (across samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> $\\normalsize\n",
    "\\begin{align}\n",
    "h_{\\theta}(X) &= \\theta \\cdot X \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "> where,\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta &\\text{ is a row vector of coefficients (parameters) of the polynomial } h_{\\theta} \\\\\n",
    "X &\\text{ is a } n \\times m \\text{ matrix of samples} \\\\\n",
    "n &\\text{ is the number of features; for univariate, } n = 2, (x_0,\\;x_1) \\\\\n",
    "m &\\text{ is the number of samples}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> **Example linreguni-2:**\n",
    ">\n",
    "> Given,\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta = \\begin{bmatrix}\n",
    "2 & 5\n",
    "\\end{bmatrix}\n",
    ",\\;\n",
    "X = \\begin{bmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "2 & 3 & 5 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$\n",
    ">\n",
    "> so $X$ contains three samples (the cols of $X$)\n",
    "\n",
    "\n",
    "> Then,\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta \\cdot X &= \\begin{bmatrix}\n",
    "  (\\theta_{[0,0]} \\times X_{[0,0]}) + (\\theta_{[0,1]} \\times X_{[1,0]}) &\n",
    "  (\\theta_{[0,0]} \\times X_{[0,1]}) + (\\theta_{[0,1]} \\times X_{[1,1]}) &\n",
    "  (\\theta_{[0,0]} \\times X_{[0,2]}) + (\\theta_{[0,1]} \\times X_{[1,2]})\n",
    "\\end{bmatrix} \\\\\n",
    "  \\;&= \\begin{bmatrix}\n",
    "    (2 \\times 1) + (5 \\times 2) &\n",
    "    (2 \\times 1) + (5 \\times 3) &\n",
    "    (2 \\times 1) + (5 \\times 5)\n",
    "  \\end{bmatrix} \\\\\n",
    "  \\;&= \\begin{bmatrix}\n",
    "    (2 + 10) & (2 + 15) & (2 + 25)\n",
    "  \\end{bmatrix} \\\\\n",
    "  \\;&= \\begin{bmatrix}\n",
    "    12 & 17 & 27\n",
    "  \\end{bmatrix}\n",
    "\\end{align}\n",
    "$\n",
    ">\n",
    "> so three predictions are returned (the cols of the result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta (shape):  (1, 2)\n",
      "[[2. 5.]] \n",
      "\n",
      "x (shape):  (1, 3)\n",
      "[[2 3 5]] \n",
      "\n",
      "X (shape) with bias terms:  (2, 3)\n",
      "[[1. 1. 1.]\n",
      " [2. 3. 5.]] \n",
      "\n",
      "y_hat (shape):  (1, 3)\n",
      "[[12. 17. 27.]]\n"
     ]
    }
   ],
   "source": [
    "# lingreguni-fw_VECT example\n",
    "\n",
    "theta = np.array([[2., 5.]])\n",
    "x = np.array(linreg_x[:, :])\n",
    "x_bias = np.ones((1, x.shape[1]))\n",
    "X = np.vstack((x_bias, x))\n",
    "print('theta (shape): ', theta.shape)\n",
    "print(theta, '\\n')\n",
    "print('x (shape): ', x.shape)\n",
    "print(x, '\\n')\n",
    "print('X (shape) with bias terms: ', X.shape)\n",
    "print(X, '\\n')\n",
    "\n",
    "y_hat = linreg_h_theta(theta, X)\n",
    "print('y_hat (shape): ', y_hat.shape)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> $\\normalsize\n",
    "\\begin{align}\n",
    "L_{\\theta}(\\hat{y}, y) &= \\hat{y} - y\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "\n",
    "> where,\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "\\hat{y} &\\text{ is the prediction from } h_{\\theta}(x) \\\\\n",
    "y &\\text{ is the training value that } h_{\\theta}(x) \\text{ should match}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.915977Z",
     "start_time": "2022-04-09T18:04:27.915962Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linreg_loss_theta(y_hat, y):\n",
    "    \"\"\"\n",
    "    :param y_hat: the prediction from h_theta\n",
    "    :param y: the training label to match\n",
    "    :return: loss, or error, of the prediction\n",
    "    \"\"\"\n",
    "\n",
    "    loss = y_hat - y\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss (shape):  (1, 1)\n",
      "[[1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# linreguni-loss\n",
    "\n",
    "theta = np.array([[2., 5.]])\n",
    "x = np.array(linreg_x[:, 0:1])\n",
    "y = np.array(linreg_y[:, 0:1])\n",
    "x_bias = np.ones((1, x.shape[1]))\n",
    "X = np.vstack((x_bias, x))\n",
    "\n",
    "y_hat = linreg_h_theta(theta, X)\n",
    "loss = linreg_loss_theta(y_hat, y)\n",
    "\n",
    "print('loss (shape): ', loss.shape)\n",
    "print(loss, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss (shape):  (1, 3)\n",
      "[[ 1.  0. -2.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# linreguni-loss_VECT (across samples)\n",
    "\n",
    "theta = np.array([[2., 5.]])\n",
    "x = np.array(linreg_x[:, :])\n",
    "y = np.array(linreg_y[:, :])\n",
    "x_bias = np.ones((1, x.shape[1]))\n",
    "X = np.vstack((x_bias, x))\n",
    "\n",
    "y_hat = linreg_h_theta(theta, X)\n",
    "loss = linreg_loss_theta(y_hat, y)\n",
    "\n",
    "print('loss (shape): ', loss.shape)\n",
    "print(loss, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> $\\normalsize\n",
    "\\begin{align}\n",
    "    \\;& \\;&\n",
    "    \\;&\\small \\underline{Normal}&\n",
    "    \\;& \\;&\n",
    "    \\;&\\small \\underline{Vectorized} \\\\ \\\\\n",
    "J(\\theta) &=&\n",
    "    \\;&\\frac{1}{2m}\\sum\\limits_{i=1}^{m} \\left[h_{\\theta}(x^{(i)}) - y^{(i)}\\right]^2 &\n",
    "    \\;&\\Rightarrow&\n",
    "    \\;&\\frac{1}{2m} \\left[ \\left( \\theta X - Y \\right) \\cdot \\left( \\theta X - Y \\right)^{T} \\right] \\\\\n",
    "    \\;&=&\n",
    "    \\;&\\frac{1}{2m}\\sum\\limits_{i=1}^{m} L_{\\theta}(\\hat{y}^{(i)}, y^{(i)})^2 &\n",
    "    \\;&\\Rightarrow&\n",
    "    \\;&\\frac{1}{2m} \\left( L_{\\theta} \\cdot L_{\\theta}^{T} \\right) \\\\\n",
    "\\end{align}\n",
    "$\n",
    ">\n",
    "> where,\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "m &\\text{ is the number of samples} \\\\\n",
    "\\\\ \\text{and} \\\\\n",
    "\\; &\\text{vectorization is across samples, } m\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.917417Z",
     "start_time": "2022-04-09T18:04:27.917401Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linreg_cost_from_loss(L_theta):\n",
    "    \"\"\"\n",
    "    :param L_theta: matrix (1 x m) of errors (loss)\n",
    "    :return: cost (mean squared error) to be minimized\n",
    "    \"\"\"\n",
    "\n",
    "    m = L_theta.shape[1]\n",
    "    cost = np.dot(L_theta, L_theta.T) / (2 * m)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.919177Z",
     "start_time": "2022-04-09T18:04:27.919155Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linreg_cost_from_inputs(theta, X, Y):\n",
    "    \"\"\"\n",
    "    :param theta: row vector (1 x n) of polynomial coefficients (i.e. parameters)\n",
    "    :param X: n x m matrix of features, with x_0's set to 1 (i.e. bias terms)\n",
    "    :param Y: row vector (1 x m) of target values\n",
    "    :return: cost (mean squared error) to be minimized\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[1]\n",
    "    cost = np.dot(np.dot(theta, X) - y, (np.dot(theta, X) - y).T) / (2 * m)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_from_loss (shape):  (1, 1)\n",
      "[[0.83333333]] \n",
      "\n",
      "cost_from_inputs (shape):  (1, 1)\n",
      "[[0.83333333]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# linreguni-cost\n",
    "\n",
    "theta = np.array([[2., 5.]])\n",
    "x = np.array(linreg_x[:, :])\n",
    "y = np.array(linreg_y[:, :])\n",
    "x_bias = np.ones((1, x.shape[1]))\n",
    "X = np.vstack((x_bias, x))\n",
    "\n",
    "y_hat = linreg_h_theta(theta, X)\n",
    "L_theta = linreg_loss_theta(y_hat, y)\n",
    "\n",
    "cost_from_loss = linreg_cost_from_loss(L_theta)\n",
    "print('cost_from_loss (shape): ', cost_from_loss.shape)\n",
    "print(cost_from_loss, '\\n')\n",
    "\n",
    "cost_from_inputs = linreg_cost_from_inputs(theta, X, y)\n",
    "print('cost_from_inputs (shape): ', cost_from_inputs.shape)\n",
    "print(cost_from_inputs, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Backward function / Learning / Parameter update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> $\\normalsize\n",
    "\\begin{align}\n",
    "    \\;& \\;&\n",
    "        \\;&\\small \\underline{Normal}&\n",
    "        \\;& \\;&\n",
    "        \\;&\\small \\underline{Vectorized} \\\\ \\\\\n",
    "dJ(\\theta)\n",
    "        &=&\n",
    "        \\;&\\frac{1}{m}\\sum\\limits_{i=1}^{m} L_{\\theta}(\\hat{y}^{(i)}, y^{(i)})x_{j}^{(i)}&\n",
    "        \\;&\\Rightarrow&\n",
    "        \\;&\\frac{1}{m} \\left( L_{\\theta} \\cdot X^{T}\\right) \\\\\n",
    "    \\;&=&\n",
    "        \\;&\\frac{1}{m}\\sum\\limits_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})x_{j}^{(i)}&\n",
    "        \\;& \\;&\n",
    "        \\;& \\; \\\\\n",
    "    \\;&=&\n",
    "        \\;&\\frac{1}{m}\\sum\\limits_{i=1}^{m} \\left[h_{\\theta}(x^{(i)}) - y^{(i)}\\right]x_{j}^{(i)}&\n",
    "        \\;&\\Rightarrow&\n",
    "        \\;&\\frac{1}{m} \\; \\left[ (\\theta X - Y) \\cdot X^{T} \\right]\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> $\\normalsize\n",
    "\\begin{align}\n",
    "    \\;& \\;&\n",
    "        \\;&\\small \\underline{Normal}&\n",
    "        \\;& \\;&\n",
    "        \\;&\\small \\underline{Vectorized} \\\\ \\\\\n",
    "\\theta_{j}\n",
    "        &:= \\theta_{j} \\; -&\n",
    "        \\;&\\alpha \\; dJ(\\theta)&\n",
    "        \\;& \\;&\n",
    "        \\;& \\; \\\\\n",
    "    \\;&:= \\theta_{j} \\; -&\n",
    "        \\;&\\boxed{\\alpha \\left( \\frac{1}{m}\\sum\\limits_{i=1}^{m} \\left[h_{\\theta}(x^{(i)}) - y^{(i)}\\right]x_{j}^{(i)} \\right) }&\n",
    "        \\;&\\Rightarrow&\n",
    "        \\;&\\boxed{\\alpha \\left( \\frac{1}{m} \\; \\left[ (\\theta X - Y) \\cdot X^{T} \\right] \\right) } \\\\\n",
    "    \\;& \\;&\n",
    "        \\; &\\small{\\text{OR}}&\n",
    "        \\;& \\;&\n",
    "        \\;& \\; \\\\\n",
    "    \\;& \\;&\n",
    "        \\;&\\boxed{\\alpha \\left( \\frac{1}{m}\\sum\\limits_{i=1}^{m} L_{\\theta}(\\hat{y}^{(i)}, y^{(i)})x_{j}^{(i)} \\right) }&\n",
    "        \\;&\\Rightarrow&\n",
    "        \\;&\\boxed{\\alpha \\left( \\frac{1}{m} \\left[ L_{\\theta} \\cdot X^{T}\\right] \\right)}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> where,\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta &\\text{ is a row vector of } n \\text{ parameters, i.e. polynomial coefficients} \\\\\n",
    "X &\\text{ is a } n \\times m \\text{ matrix of samples} \\\\\n",
    "Y &\\text{ is a row vector of } m \\text{ target values} \\\\\n",
    "m &\\text{ is the number of samples} \\\\\n",
    "n &\\text{ is the number of features (incl. bias terms), i.e. polynomial terms} \\\\\n",
    "i &\\text{ is the index } (1..m) \\text{ of the samples} \\\\\n",
    "j &\\text{ is the index } (1..n) \\text{ of the features, i.e. polynomial terms} \\\\\n",
    "\\alpha &\\text{ is the learning rate}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.920524Z",
     "start_time": "2022-04-09T18:04:27.920508Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linreg_grad_from_loss(L_theta, X):\n",
    "    \"\"\"\n",
    "    :param L_theta: row vector (1 x m) of errors (loss)\n",
    "    :param X: n x m matrix of input features\n",
    "    :return: gradient at the current theta\n",
    "    \"\"\"\n",
    "\n",
    "    m = L_theta.shape[1]\n",
    "    grad = np.dot(L_theta, X.T) / m\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.922038Z",
     "start_time": "2022-04-09T18:04:27.922020Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linreg_grad_from_inputs(theta, X, Y):\n",
    "    \"\"\"\n",
    "    :param theta: row vector (1 x n) of parameters\n",
    "    :param X: n x m matrix of input features\n",
    "    :param Y: row vector (1 x m) of target values\n",
    "    :return: gradient at the current theta\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[1]\n",
    "    grad = np.dot(np.dot(theta, X) - Y, X.T) / m\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.923280Z",
     "start_time": "2022-04-09T18:04:27.923264Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linreg_grad_validate(theta, X, Y, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    :param theta: row vector of parameters\n",
    "    :param X: n x m matrix of inputs\n",
    "    :param Y: row vector of target values\n",
    "    :param epsilon: real value << 0\n",
    "    :return: row vector gradient estimates for cost function at current theta\n",
    "    \"\"\"\n",
    "\n",
    "    n = theta.shape[1]\n",
    "    grad_validation = np.zeros(theta.shape)\n",
    "\n",
    "    for i in range(n):\n",
    "        theta_plus_epsilon = np.copy(theta)\n",
    "        theta_minus_epsilon = np.copy(theta)\n",
    "        theta_plus_epsilon[0, i] = theta[0, i] + epsilon\n",
    "        theta_minus_epsilon[0, i] = theta[0, i] - epsilon\n",
    "\n",
    "        cost_plus_epsilon = linreg_cost_from_inputs(theta_plus_epsilon, X, Y)\n",
    "        cost_minus_epsilon = linreg_cost_from_inputs(theta_minus_epsilon, X, Y)\n",
    "\n",
    "        grad_validation[0, i] = (cost_plus_epsilon - cost_minus_epsilon) / (2 * epsilon)\n",
    "\n",
    "    return grad_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T13:13:58.944014Z",
     "start_time": "2022-04-06T13:13:58.936561Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_from_loss (shape):  (1, 2)\n",
      "[[-0.33333333 -2.66666667]] \n",
      "\n",
      "grad_from_inputs (shape):  (1, 2)\n",
      "[[-0.33333333 -2.66666667]] \n",
      "\n",
      "grad_validation (shape):  (1, 2)\n",
      "[[-0.33333333 -2.66666667]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# linreguni-grad\n",
    "\n",
    "theta = np.array([[2., 5.]])\n",
    "x = np.array(linreg_x[:, :])\n",
    "y = np.array(linreg_y[:, :])\n",
    "x_bias = np.ones((1, x.shape[1]))\n",
    "X = np.vstack((x_bias, x))\n",
    "\n",
    "y_hat = linreg_h_theta(theta, X)\n",
    "L_theta = linreg_loss_theta(y_hat, y)\n",
    "\n",
    "grad_from_loss = linreg_grad_from_loss(L_theta, X)\n",
    "print('grad_from_loss (shape): ', grad_from_loss.shape)\n",
    "print(grad_from_loss, '\\n')\n",
    "\n",
    "grad_from_inputs = linreg_grad_from_inputs(theta, X, y)\n",
    "print('grad_from_inputs (shape): ', grad_from_inputs.shape)\n",
    "print(grad_from_inputs, '\\n')\n",
    "\n",
    "grad_validation = linreg_grad_validate(theta, X, y)\n",
    "print('grad_validation (shape): ', grad_validation.shape)\n",
    "print(grad_validation, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:04:27.924822Z",
     "start_time": "2022-04-09T18:04:27.924804Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def linreg_update_params(theta, grad, alpha):\n",
    "    \"\"\"\n",
    "    :param theta: row vector (1 x n) of current parameters\n",
    "    :param grad: row vector (1 x n) of gradients\n",
    "    :param alpha: learning rate as real number\n",
    "    :return: row vector of updated parmeters\n",
    "    \"\"\"\n",
    "\n",
    "    params = theta - alpha * grad\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_from_inputs (shape):  (1, 2)\n",
      "[[-0.33333333 -2.66666667]] \n",
      "\n",
      "theta (shape):  (1, 2)\n",
      "[[2. 5.]] \n",
      "\n",
      "params (shape):  (1, 2)\n",
      "[[2.00333333 5.02666667]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# linreguni-param-update\n",
    "\n",
    "theta = np.array([[2., 5.]])\n",
    "x = np.array(linreg_x[:, :])\n",
    "y = np.array(linreg_y[:, :])\n",
    "x_bias = np.ones((1, x.shape[1]))\n",
    "X = np.vstack((x_bias, x))\n",
    "alpha = 0.01\n",
    "\n",
    "grad_from_inputs = linreg_grad_from_inputs(theta, X, y)\n",
    "print('grad_from_inputs (shape): ', grad_from_inputs.shape)\n",
    "print(grad_from_inputs, '\\n')\n",
    "\n",
    "params = linreg_update_params(theta, grad_from_inputs, alpha)\n",
    "print('theta (shape): ', theta.shape)\n",
    "print(theta, '\\n')\n",
    "print('params (shape): ', params.shape)\n",
    "print(params, '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
